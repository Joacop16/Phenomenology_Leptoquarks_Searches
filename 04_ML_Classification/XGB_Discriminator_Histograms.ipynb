{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6716b3b-5f41-4a4c-af1e-69ff2502c918",
   "metadata": {},
   "source": [
    "$$\\textrm{Joaquin Pe√±uela Parra}$$\n",
    "$$\\textrm{University of Los Andes}$$\n",
    "$$\\textrm{High Energy Physics Group: Phenomenology of Particles}$$\n",
    "\n",
    "This code was written to be running in Docker. If you do not have a Docker inside hep-server2 please refer to: https://github.com/Phenomenology-group-uniandes/Tutoriales_Generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "753a5d42-946a-43d2-8a9f-80e1a80f2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "def add_parent_lib_path(name=\"Leptoquarks_Searches_2023\"):\n",
    "    sys.path.append(sys.path[0].split(name)[0])\n",
    "    \n",
    "add_parent_lib_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89acd650-fd08-4367-9136-953b8a965ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_Leptoquarks_searches = os.path.dirname(os.path.dirname(os.path.realpath('XBG_Discriminator_Histograms.ipynb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203aa837-feb7-4963-93e9-7ecc2f31d928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/06\n"
     ]
    }
   ],
   "source": [
    "from Uniandes_Framework.ml_tools import tools\n",
    "from Uniandes_Framework.delphes_reader import root_analysis\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from ROOT import TCanvas #Permite poner los histogramas\n",
    "from ROOT import THStack #Permite graficar varios histogramas al mismo tiempo\n",
    "from ROOT import TLegend #Permite poner legends cuando se sobrelapan histogramas\n",
    "from ROOT import TLatex #Permite poner avisos en Latex en las graficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa195a7-4406-49b0-9a30-b3cedd1b54e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [\"hadronic_dLQ\", \"hadronic_sLQ\", \"hadronic_non-resonant\", \"semileptonic_dLQ\", \"semileptonic_sLQ\", \"semileptonic_non-resonant\"]\n",
    "signals = ['LQ_LQ', 'Tau_LQ', 'Tau_Tau'] + ['LQ_LQ_wo_RHC', 'Tau_LQ_wo_RHC', 'Tau_Tau_wo_RHC']\n",
    "Masses = [\n",
    "    \"1000\" ,\n",
    "    '1250', \n",
    "    '1500', \n",
    "    '1750', \n",
    "    '2000', \n",
    "    '2250', \n",
    "    '2500'\n",
    "]\n",
    "bkgs = ['ttbar', 'z_jets', 'w_jets', 'stop','ww', 'wz', 'zz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8821e8b-b016-4eaa-a46c-e37fcc94d4cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pT_{#tau_{1}}(GeV)', '#Delta R_{#tau_{1}b_{2}}', '#eta_{b_{2}}', '#Delta #phi_{#tau_{1}b_{1}}', '#Delta R_{#tau_{1}b_{1}}', '#Delta #eta_{#tau_{1}#tau_{2}}', '#Delta #phi_{b_{1}MET}', '#Delta #phi_{b_{2}MET}', '#phi_{#tau_{1}}', '#phi_{#tau_{2}}', 'sT(GeV)']\n",
      "['sT(GeV)', 'Q_{#tau_{1}}Q_{#tau_{2}}', '#Delta #phi_{b_{1}MET}', '#Delta R_{#tau_{1}b_{1}}', '#Delta #phi_{#tau_{2}MET}', '#Delta #eta_{#tau_{1}#tau_{2}}', '#Delta R_{#tau_{2}b_{1}}', '#phi_{#tau_{1}}', '#Delta #phi_{#tau_{1}b_{1}}', '#phi_{#tau_{2}}']\n",
      "['sT(GeV)', '#Delta R_{#tau_{1}#tau_{2}}', 'Q_{#tau_{1}}Q_{#tau_{2}}', '#Delta #phi_{#tau_{2}MET}', '#Delta #phi_{#tau_{1}#tau_{2}}', '#Delta pT_{#tau_{2}MET}(GeV)', '#phi_{#tau_{1}}', '#eta_{#tau_{1}}', '#phi_{MET}', '#phi_{#tau_{2}}']\n",
      "['sT(GeV)', 'Q_{lep_{1}}Q_{#tau_{1}}', '#Delta pT_{b_{2}MET}(GeV)', '#Delta #phi_{lep_{1}#tau_{1}}', '#Delta R_{#tau_{1}b_{1}}', '#Delta #eta_{b_{1}b_{2}}', '#Delta #phi_{lep_{1}MET}', '#Delta #eta_{lep_{1}#tau_{1}}', '#phi_{MET}', '#phi_{b_{2}}']\n",
      "['sT(GeV)', 'Q_{lep_{1}}Q_{#tau_{1}}', '#Delta #phi_{lep_{1}#tau_{1}}', '#Delta #phi_{lep_{1}MET}', '#Delta R_{#tau_{1}b_{1}}', '#Delta #eta_{lep_{1}b_{1}}', '#phi_{#tau_{1}}', '#eta_{#tau_{1}}', '#phi_{lep_{1}}', '#phi_{MET}']\n",
      "['sT(GeV)', 'Q_{lep_{1}}Q_{#tau_{1}}', '#Delta R_{lep_{1}#tau_{1}}', '#Delta #phi_{lep_{1}MET}', '#Delta #phi_{lep_{1}#tau_{1}}', '#Delta pT_{lep_{1}MET}(GeV)', '#Delta #eta_{lep_{1}#tau_{1}}', '#phi_{lep_{1}}', '#phi_{#tau_{1}}', '#phi_{MET}']\n"
     ]
    }
   ],
   "source": [
    "try: os.mkdir('Histograms')\n",
    "except: pass\n",
    "\n",
    "def escape_braces(strings):\n",
    "    escaped_strings = []\n",
    "    for s in strings:\n",
    "        escaped_s = s.replace('{', '{{').replace('}', '}}')\n",
    "        escaped_strings.append(\"{}\".format(escaped_s))\n",
    "    return escaped_strings\n",
    "\n",
    "\n",
    "for channel in channels:\n",
    "    try: os.mkdir(f'Histograms/{channel}')\n",
    "    except: pass    \n",
    "\n",
    "    bkg_dict = {}\n",
    "    for bkg in bkgs: bkg_dict[bkg] = os.path.join(os.sep,\"disco4\",\"pheno_csv_files\",\"Leptoquarks_Searches\",bkg,f\"{bkg}_{channel}.csv\")\n",
    "    \n",
    "    most_important_features = []\n",
    "    with open(os.path.join(os.getcwd(), 'XGB_models', channel, f'Most_Important_Features.txt'), \"r\") as f:\n",
    "        for line in f: most_important_features.append(line.strip())\n",
    "    f.close()\n",
    "    print(most_important_features)\n",
    "    #most_important_features = escape_braces(most_important_features)                      \n",
    "    for Mass in Masses:\n",
    "        try: os.mkdir(f'Histograms/{channel}/M{Mass}')\n",
    "        except: pass\n",
    "\n",
    "        signal_dict = {}\n",
    "        for signal in signals: \n",
    "            signal_dict[f\"{signal}_{Mass}\"] = os.path.join(os.sep,\"disco4\",\"pheno_csv_files\",\"Leptoquarks_Searches\",f\"{signal}_{Mass}\",f\"{signal}_{Mass}_{channel}.csv\")\n",
    "\n",
    "        path_model_mass =  os.path.join(os.getcwd(), 'XGB_models', channel, f'M{Mass}_XGB.joblib')\n",
    "        bkg_and_signal_dict = bkg_dict | signal_dict\n",
    "        path_folder_mass = os.path.join(os.getcwd(), 'Histograms', channel, f'M{Mass}')\n",
    "        \n",
    "        with root_analysis.Quiet(): tools.hist_discriminator(path_model= path_model_mass, csv_dict = bkg_and_signal_dict, path_to_save= path_folder_mass, best_features= most_important_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
