{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05880998-f2bc-4854-867e-69d17cddf537",
   "metadata": {},
   "source": [
    "$$\\textrm{Joaquin PeÃ±uela Parra, Cristian Fernando Rodriguez Cruz}$$\n",
    "$$\\textrm{University of Los Andes}$$\n",
    "$$\\textrm{High Energy Physics Group: Phenomenology of Particles}$$\n",
    "\n",
    "This code was written to be running in Docker. If you do not have a Docker inside hep-server2 please refer to: https://github.com/Phenomenology-group-uniandes/Tutoriales_Generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb98ed4d-39b5-44c3-b6a2-e0cc0e94700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf Uniandes_Framework\n",
    "!git clone https://github.com/Phenomenology-group-uniandes/Uniandes_Framework.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d9c38-fea8-4cd1-8d26-abb4ea3998d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(f'{os.getcwd()}/Uniandes_Framework')\n",
    "\n",
    "from delphes_reader import DelphesLoader \n",
    "from delphes_reader import clasificator \n",
    "from delphes_reader import root_analysis \n",
    "from delphes_reader import Quiet \n",
    "\n",
    "from ROOT import TChain\n",
    "from ROOT import TLorentzVector\n",
    "\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c35f44-4bdf-46f9-a729-e71618d3fad9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def event_selection(signal):\n",
    "    \n",
    "    csv_folder_path = f'/disco4/pheno_csv_files/Leptoquarks_Searches/{signal}/'\n",
    "    !mkdir -p {csv_folder_path}    \n",
    "    \n",
    "    with Quiet():\n",
    "    \n",
    "        CUTS={\"l_jet\":     {\"pt_min_cut\":30., \"eta_min_cut\":-5.,  \"eta_max_cut\":+5. },\n",
    "              \"b_jet\":     {\"pt_min_cut\":30., \"eta_min_cut\":-2.4, \"eta_max_cut\":+2.4},\n",
    "              \"tau_jet\":   {\"pt_min_cut\":50., \"eta_min_cut\":-2.3, \"eta_max_cut\":+2.3},\n",
    "              \"other_jet\": {\"pt_min_cut\":0.,  \"eta_min_cut\":-5.,  \"eta_max_cut\":+5.},\n",
    "              \"electron\":  {\"pt_min_cut\":35.,  \"eta_min_cut\":-2.4, \"eta_max_cut\":+2.4},\n",
    "              \"muon\":      {\"pt_min_cut\":30.,  \"eta_min_cut\":-2.4, \"eta_max_cut\":+2.4}}\n",
    "\n",
    "        ST = []\n",
    "        \n",
    "        Delphes = DelphesLoader(signal)\n",
    "        Paths = Delphes.Forest\n",
    "        xs = Delphes.xs   \n",
    "        \n",
    "        #We want a Cutflows file for each cathegory:        \n",
    "        Cutflows = {'hadronic_non-resonant': {'XS': xs},\n",
    "                    'hadronic_sLQ': {'XS': xs},\n",
    "                    'hadronic_dLQ': {'XS': xs},\n",
    "                    'semileptonic_non-resonant': {'XS': xs},\n",
    "                    'semileptonic_sLQ': {'XS': xs},\n",
    "                    'semileptonic_dLQ': {'XS': xs}}\n",
    "        \n",
    "        kinematic_variables = {}\n",
    "        for key in Cutflows.keys(): kinematic_variables[key] = []\n",
    "        \n",
    "        for path in Paths:\n",
    "\n",
    "            tree = TChain(\"Delphes;1\") \n",
    "            tree.Add(path) \n",
    "                        \n",
    "            for event in tree:\n",
    "                \n",
    "                for key in Cutflows.keys(): Cutflows[key]['All'] = Cutflows[key].get('All',0) + 1\n",
    "                    \n",
    "                leptons = clasificator.get_good_leptons(event, kin_cuts= CUTS) \n",
    "                \n",
    "                if(len(leptons) > 1): continue\n",
    "                for key in Cutflows.keys(): Cutflows[key]['Maximum 1 light lepton'] = Cutflows[key].get('Maximum 1 light lepton',0) + 1\n",
    "                           \n",
    "                jets = clasificator.get_good_jets(event, kin_cuts= CUTS)\n",
    "                \n",
    "                #Adding tau_jets like leptons:\n",
    "                leptons = leptons + jets['tau_jet'] \n",
    "                \n",
    "                if(len(leptons) != 2): continue \n",
    "                for key in Cutflows.keys(): Cutflows[key]['Exactly 2 leptons'] = Cutflows[key].get('Exactly 2 leptons',0) + 1\n",
    "\n",
    "                #At this point, we have two hadronic taus or one hadronic tau and one lepton. Now, we can clasificate:\n",
    "                \n",
    "                #clasification:\n",
    "                if(len(jets['tau_jet']) == 1): \n",
    "                    label1 = 'semileptonic'\n",
    "                else:\n",
    "                    label1 = 'hadronic'  \n",
    "                \n",
    "                    \n",
    "                cut = f'{label1} selection'    \n",
    "                for key in Cutflows.keys(): \n",
    "                    if label1 in key: Cutflows[key][cut] = Cutflows[key].get(cut, 0) + 1\n",
    "                \n",
    "                if(len(jets['b_jet']) == 0):\n",
    "                    label2 = 'non-resonant'\n",
    "                elif(len(jets['b_jet']) == 1):\n",
    "                    label2 = 'sLQ'\n",
    "                elif(len(jets['b_jet']) == 2):\n",
    "                    label2 = 'dLQ'\n",
    "                else: continue\n",
    "                \n",
    "                label = f'{label1}_{label2}'  \n",
    "                \n",
    "                cut = f'{label2} selection'    \n",
    "                Cutflows[label][cut] = Cutflows[label].get(cut, 0) + 1                \n",
    "                \n",
    "                if(leptons[0].DeltaR(leptons[1]) < 0.3): continue #DeltaR > 0.3\n",
    "                cut = 'DeltaR > 0.3'\n",
    "                Cutflows[label][cut] = Cutflows[label].get(cut,0) + 1\n",
    "                \n",
    "                MET = clasificator.get_met(event)\n",
    "                MET.SetName('MET')\n",
    "                particles = leptons + jets['b_jet'] + [MET]\n",
    "                \n",
    "                ST = 0\n",
    "                for particle in particles: ST += particle.pt()\n",
    "                \n",
    "                HT = 0\n",
    "                for particle in jets['l_jet']: HT += particle.pt()\n",
    "                \n",
    "                TLV = TLorentzVector(0,0,0,0)\n",
    "                for particle in particles: TLV += particle.GetTLV()\n",
    "                MT = TLV.Mt()\n",
    "                \n",
    "                Mass_invariant = (leptons[0].GetTLV() + leptons[1].GetTLV()).M()\n",
    "                \n",
    "                row = root_analysis.get_kinematics_row(particles)\n",
    "                \n",
    "                keylist = list(row.keys())\n",
    "                for key in keylist: \n",
    "                    if (\"Mass\" in key): row.pop(key,None)\n",
    "                \n",
    "                row[\"sT(GeV)\"] = ST\n",
    "                row[\"hT(GeV)\"] = HT\n",
    "                row[\"mT(GeV)\"] = MT\n",
    "                row[\"light_jets_multiplicity\"] = len(jets['l_jet'])\n",
    "                name = leptons[0].Name + leptons[1].Name\n",
    "                row[f\"Mass_{{{name}}}(GeV)\"] = Mass_invariant\n",
    "                row[f\"Q_{{{leptons[0].Name}}}Q_{{{leptons[1].Name}}}\"] = leptons[0].Charge*leptons[1].Charge\n",
    "                \n",
    "                \n",
    "                kinematic_variables[label].append(row)\n",
    "                                \n",
    "        for key in Cutflows.keys(): root_analysis.generate_csv(kinematic_variables[key], os.path.join(csv_folder_path, f'{signal}_{key}.csv'))\n",
    "                \n",
    "    return {signal: Cutflows}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26e5764-de71-4b85-aaf0-3c911ed09b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Masses = ['1250', '1500', '1750', '2000', '2250', '2500']\n",
    "LQ_signals = ['LQ_LQ', 'Tau_LQ', 'Tau_Tau']\n",
    "\n",
    "signals = []\n",
    "\n",
    "for signal in LQ_signals:\n",
    "    for M in Masses:\n",
    "        signals.append(f'{signal}_{M}')\n",
    "        \n",
    "signals = signals + ['ttbar', 'stop','z_jets', 'w_jets', 'ww', 'wz', 'zz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b92af00-bc4c-40d7-85fd-c437388e6685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with Pool(6) as p:\n",
    "    mapping = list(p.map(event_selection, signals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc5943c-2c07-4f8f-a1a0-3d7dfcc2392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['hadronic_non-resonant','hadronic_sLQ','hadronic_dLQ','semileptonic_non-resonant','semileptonic_sLQ','semileptonic_dLQ']\n",
    "\n",
    "Dict_Cutflows = {}\n",
    "\n",
    "for label in labels: Dict_Cutflows[label] = {}\n",
    "\n",
    "for Cutflows_Signal_Directory in mapping:\n",
    "    \n",
    "    signal = list(Cutflows_Signal_Directory.keys())[0]\n",
    "    \n",
    "    for label in labels: Dict_Cutflows[label][signal] = Cutflows_Signal_Directory[signal][label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc91829-e5eb-4ed9-883a-9ba231bf619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder_path = f'/disco4/pheno_csv_files/Leptoquarks_Searches/'\n",
    "\n",
    "Dict_DataFrames_Cutflows = {}\n",
    "\n",
    "for key in Dict_Cutflows: \n",
    "    Dict_DataFrames_Cutflows[key] = pd.DataFrame.from_dict(Dict_Cutflows[key])\n",
    "    carpeta = os.path.join(csv_folder_path, 'cutflows')\n",
    "    try: os.mkdir(carpeta)\n",
    "    except: pass\n",
    "    Dict_DataFrames_Cutflows[key].to_csv(os.path.join(carpeta, f'{key}.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
