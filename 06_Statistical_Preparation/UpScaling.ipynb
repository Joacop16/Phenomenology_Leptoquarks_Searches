{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e00f2e-e145-46a3-81e7-0db512cdf48a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace9842a-c327-4cbb-8250-04e2f77558c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lq_folder = os.path.dirname(os.getcwd())\n",
    "folder_DATA = os.path.join(lq_folder,\"05_ML_Final_Distribution\")\n",
    "n_events_folder = os.path.join(lq_folder,\"03_delphes_preselection\",\"N_events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34d5c0e2-6ceb-4142-9a30-aaac469088cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_path = pathlib.Path(folder_DATA)\n",
    "data_dict = dict([( str(file), np.loadtxt(file)) for file in list(folder_path.glob('**/*.txt')) if not \".ipynb_checkpoints\" in str(file)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d85bd36-0913-4d0d-b049-ece2530d2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass (path):\n",
    "    return os.path.basename(os.path.dirname(path)).split(\"M\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbcd0062-7127-467d-91cb-6f8e6893d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel (path):\n",
    "    path = os.path.dirname(path)\n",
    "    return os.path.basename(os.path.dirname(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a06ae6-0ac0-4056-ad7d-581d597f6631",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/semileptonic_dLQ/M2500/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/semileptonic_dLQ/M1500/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/semileptonic_dLQ/M1250/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/semileptonic_dLQ/M1750/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/semileptonic_dLQ/M2000/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/semileptonic_dLQ/M2250/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/hadronic_sLQ/M2500/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/hadronic_sLQ/M1500/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/hadronic_sLQ/M1250/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/hadronic_sLQ/M2000/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/hadronic_sLQ/M2250/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/hadronic_dLQ/M2500/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/hadronic_dLQ/M1500/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/hadronic_dLQ/M1250/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/hadronic_dLQ/M1750/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/hadronic_dLQ/M2000/high_per_bin_Diboson.txt\n",
      "/disco4/SIMULACIONES/Cristian/Github/Leptoquarks_Searches_2023/05_ML_Final_Distribution/Histograms/hadronic_dLQ/M2250/high_per_bin_Diboson.txt\n"
     ]
    }
   ],
   "source": [
    "for key in data_dict.keys():\n",
    "    #\n",
    "    mass=get_mass(key)\n",
    "    channel = get_channel(key)\n",
    "    signal = key.split(\"high_per_bin_\")[-1].rstrip(\".txt\")\n",
    "    df = pd.read_csv(os.path.join(n_events_folder,f\"{channel}.csv\"), index_col=0)\n",
    "    if signal == \"stop\":\n",
    "        n_events  = float(df[\"stop\"][\"DeltaR > 0.3\"])\n",
    "    elif signal == \"tbar\":\n",
    "        n_events  = float(df[\"ttbar\"][\"DeltaR > 0.3\"])\n",
    "    elif signal == \"V+jets\":\n",
    "        n_events  = float(df[\"z_jets\"][\"DeltaR > 0.3\"]) \n",
    "        n_events += float(df[\"w_jets\"][\"DeltaR > 0.3\"])\n",
    "    elif signal == \"Diboson\":\n",
    "        n_events  = float(df[\"ww\"][\"DeltaR > 0.3\"]) \n",
    "        n_events += float(df[\"wz\"][\"DeltaR > 0.3\"])\n",
    "        n_events += float(df[\"zz\"][\"DeltaR > 0.3\"])\n",
    "    elif signal == \"Lq_Lq\":\n",
    "        n_events = float(df[f\"LQ_LQ_{mass}\"][\"DeltaR > 0.3\"])\n",
    "    elif signal == \"tau_Lq\":\n",
    "        n_events = float(df[f\"Tau_LQ_{mass}\"][\"DeltaR > 0.3\"])\n",
    "    elif signal == \"tau_tau\":\n",
    "        n_events = float(df[f\"Tau_Tau_{mass}\"][\"DeltaR > 0.3\"])\n",
    "    elif signal == \"Combined\":\n",
    "        n_events  = float(df[f\"LQ_LQ_{mass}\"][\"DeltaR > 0.3\"])\n",
    "        n_events += float(df[f\"Tau_LQ_{mass}\"][\"DeltaR > 0.3\"])\n",
    "        n_events += float(df[f\"Tau_Tau_{mass}\"][\"DeltaR > 0.3\"])\n",
    "    else:\n",
    "        n_events = 1\n",
    "        print(f\"{signal} don't have def to n_events\")\n",
    "    #\n",
    "    data = data_dict[key]\n",
    "    new_data = [0]\n",
    "    for n, dat in enumerate(data):\n",
    "        if n <= len(data)*2./3.:\n",
    "            new_data[0]+= dat\n",
    "        else:\n",
    "            new_data.append(dat)\n",
    "    new_data = np.array(new_data)\n",
    "    new_data *= n_events/sum(new_data)\n",
    "    if (0. in list(new_data)):\n",
    "        print(key)\n",
    "    #\n",
    "    new_path = key.replace(\"05_ML_Final_Distribution\",\"06_Statistical_Preparation\")\n",
    "    os.makedirs(os.path.dirname(new_path), exist_ok=True)\n",
    "    np.savetxt(new_path,new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6580bf8-b613-4505-8d5b-520743fc491a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
